{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a714ace-3dc6-4935-9ec4-f880f5002565",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4953cb2-6538-4bed-8b1e-7b49ddc64255",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c68986-d764-4681-a6b7-c6e44e28e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging is a technique used with decision trees that significantly raises the stability of models in improving accuracy and \n",
    "reducing variance, which eliminates the challenge of overfitting. Bagging reduces overfitting by averaging or voting, however,\n",
    "this leads to an increase in bias, which is compensated by the reduction in variance though. Bagging can reduce the variance within\n",
    "a learning algorithm, which is particularly helpful with high-dimensional data, where missing values can lead to higher variance,\n",
    "making it more prone to overfitting and preventing accurate generalization to new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff1c39-c416-4e50-9970-33c639c17271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079a518-6a80-442c-bd32-88469cd873b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8dfd3-914e-435a-868b-770ca4eb353b",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ecefa-a162-413a-b23b-7b1f53242535",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging is a technique used in machine learning to improve accuracy and make the model more generalize by reducing the variance, \n",
    "i.e., avoiding overfitting. It works by taking multiple subsets of the training dataset. The biggest advantage of bagging is that \n",
    "multiple weak learners can work better than a single strong learner. It provides stability and increases the machine learning algorithmâ€™s \n",
    "accuracy that is used in statistical classification and regression. It helps in reducing variance, i.e. it avoids overfitting. \n",
    "However, one disadvantage of bagging is that it introduces a loss of interpretability of a model.\n",
    "\n",
    "Different types of base learners can be used in bagging such as decision trees, neural networks, support vector machines (SVMs), etc.\n",
    "The choice of base learner depends on the problem at hand and the data available. For example, decision trees are often used as base \n",
    "learners because they are easy to interpret and can handle both categorical and numerical data. Neural networks are often used when \n",
    "dealing with complex data such as images or speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615be83e-d38d-4930-81d2-1c7a581cad28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cfb13-73ba-4970-81d9-7746de205b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24ca5d-5095-41f8-a3f1-12ba05adc09b",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111332de-7a3c-4fda-aa08-2fed7c745354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging is a technique that reduces the variance of an estimator by generating additional training data from the original data\n",
    "set using bootstrapping. The choice of base learner affects the bias-variance tradeoff in bagging. A base learner with high variance\n",
    "and low bias is preferred in bagging because it reduces the variance of the ensemble model. This is because bagging reduces the variance\n",
    "of the estimator by averaging over multiple models. If the base learner has high bias and low variance, then bagging will not be effective\n",
    "in reducing the variance of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e8598-182e-4353-9944-fc44c0fe8341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909b95c-ebeb-4041-9e1b-9a14b4b94b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6897f-23d3-438b-aa84-fbd1aa0ecc7d",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b3897-c206-45a1-b74a-86345aef885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, bagging can be used for both classification and regression tasks. In classification tasks, bagging is used to reduce the variance\n",
    "of the model by aggregating multiple models trained on different subsets of the training data. In regression tasks, bagging is used to\n",
    "reduce the variance of the model by aggregating multiple models trained on different subsets of the training data. The difference between\n",
    "bagging in classification and regression tasks is that in classification tasks, the final prediction is made by majority voting of the\n",
    "predictions made by each model in the ensemble while in regression tasks, the final prediction is made by averaging the predictions made\n",
    "by each model in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb068c5-4e7f-441a-9055-7c13ea8dcd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cb52a-f235-4275-9ec2-9164f8eb38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cba83e-157a-4177-8ab7-daae1266beaf",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ec312-7f74-4f75-a89d-4a64ac9d04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "In bagging, the ensemble size is the number of models that are trained on different subsets of the training data. \n",
    "The number of models for the ensemble is decided in the Chunk Loop Start node. For N models, the Chunk Loop Start node trains \n",
    "each one of them on a 1/N fraction of the training set. All models are collected by the Model Loop End node1.\n",
    "\n",
    "The number of models in an ensemble depends on the problem and the data. In general, increasing the number of models in an ensemble\n",
    "can improve performance up to a point, after which performance plateaus or even decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b08300-49a1-459f-b5a2-4ce41839964f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e181e-03b6-43cb-b0b2-9c26251ce339",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17bd96-6c97-4936-9eb9-2e3bf52ef1fb",
   "metadata": {},
   "source": [
    "ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab38bc3-dc57-4865-b1ea-e29596a49777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1feb9b-a90e-4dc3-82b6-3b8d7605cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8bf42-3c3a-48fb-aefa-91417340152a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2532f95-f44a-4931-b3a2-634a3dfcdb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcc5b0-e3db-479a-b1c6-fc1b2002e5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccc192-3cb9-4595-b2f0-6142905be012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32646e8f-d437-4a7a-9480-01e61af97018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1204399-0401-41f8-b802-08da16e6db0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
